{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be656135-15c4-4ff5-a818-48da5976367b",
   "metadata": {},
   "source": [
    "# Pipeline & Test\n",
    "____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91de189-9b5a-41cd-9e4c-036aa219f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import resreg\n",
    "import itertools\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c6569f-57f3-4dc6-b0cb-a3c468ff5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_aware_train_test_split(df, year_predict, provide_X_y=False):\n",
    "    # Train test split\n",
    "    df_train = df[df['year'] < year_predict].copy()\n",
    "    df_test = df[df['year'] == year_predict].copy()\n",
    "    \n",
    "    if provide_X_y:\n",
    "        # Obtain X_train, X_test, y_train, y_test\n",
    "        y_train = df_train['Productivity']\n",
    "        y_test = df_test['Productivity']\n",
    "\n",
    "        X_train = df_train.drop(columns=['市町村名', 'Productivity', 'year'])\n",
    "        X_test = df_test.drop(columns=['市町村名', 'Productivity', 'year'])\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007cb51b-8014-4dbf-a616-db394a18ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmed_add_city_historical_mean_feature(df_train, df_test, year_predict):\n",
    "    \"\"\"\n",
    "    Adds a feature representing the historical trimmed mean productivity per city\n",
    "    for a given prediction year, avoiding lookahead bias.\n",
    "\n",
    "    For each city, the minimum and maximum productivity values are excluded \n",
    "    before calculating the mean.\n",
    "\n",
    "    Returns:\n",
    "        tuple (pd.DataFrame, pd.DataFrame): Modified training and test DataFrames with the new feature.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dictionary: trimmed mean productivity per city (excluding min and max)\n",
    "    mean_yield_by_city = {}\n",
    "    for city, group in df_train.groupby('市町村名')['Productivity']:\n",
    "        if len(group) > 2:\n",
    "            trimmed_group = group.drop([group.idxmin(), group.idxmax()])\n",
    "            mean_yield_by_city[city] = trimmed_group.mean()\n",
    "        else:\n",
    "            # If there are only 2 or fewer values, just take the regular mean\n",
    "            mean_yield_by_city[city] = group.mean()\n",
    "\n",
    "    # Assign the trimmed mean values to training set\n",
    "    df_train['trimmed_mean_productivity_city'] = df_train['市町村名'].map(mean_yield_by_city)\n",
    "\n",
    "    # Apply the same trimmed mean values to test set\n",
    "    df_test['trimmed_mean_productivity_city'] = df_test['市町村名'].map(mean_yield_by_city)\n",
    "    \n",
    "    # Separate features and target\n",
    "    y_train = df_train['Productivity']\n",
    "    y_test = df_test['Productivity']\n",
    "\n",
    "    X_train = df_train.drop(columns=['市町村名', 'Productivity', 'year'])\n",
    "    X_test = df_test.drop(columns=['市町村名', 'Productivity', 'year'])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feb3357-20ca-4cdd-962f-1ce46cbe134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_yearly_averages(df, features_to_average):\n",
    "    \"\"\"\n",
    "    Computes the year average for selected features and adds them\n",
    "    as new features with suffix '_year_average'.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original DataFrame with a 'year' column.\n",
    "        features_to_average (list): List of feature names (str) to compute year averages.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with new '_year_average' features added.\n",
    "    \"\"\"\n",
    "    # Compute mean per year only for selected features\n",
    "    yearly_means = df.groupby('year')[features_to_average].mean()\n",
    "    yearly_means = yearly_means.add_prefix('year_average_').reset_index()\n",
    "\n",
    "    # Merge back into the original DataFrame\n",
    "    df = df.merge(yearly_means, on='year', how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c123376d-ea9c-4c97-b650-a6bc41bea6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGBMR_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Quickly evaluates the performance of a model after preprocessing,\n",
    "    using a balanced LightGBM configuration.\n",
    "    \"\"\"\n",
    "    model = LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        num_leaves=31,\n",
    "        max_depth=4,\n",
    "        min_child_samples=30,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.8,\n",
    "        learning_rate=0.10,\n",
    "        n_estimators=100,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=0.0,\n",
    "        random_state=42,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    print(f\"✅ Preprocessing Assessment — RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c00205-04ea-4d25-8caa-d25f7143246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_less_important = [\"市町村コード\", \"NDVI_li_9\", \"NDVI_li_10\",\n",
    "                           \"ET0_sum_veg\", \"ET0_sum_rep\", \"PTI_sum_veg\", \"PTI_sum_rep\",\n",
    "                           \"SWD_sum_veg\", \"SWD_sum_rep\", \"SWD_mean_rep\", \"SWD_mean_veg\",\n",
    "                           \"T2M_days_ideal_vegetative\", \"T2M_days_ideal_reproductive\",\n",
    "                           \"T2M_days_low_vegetative\", \"T2M_days_low_reproductive\",\n",
    "                           \"T2M_days_extremely_low_vegetative\", \"T2M_days_extremely_low_reproductive\",\n",
    "                           \"ALLSKY_days_ideal_veg\", \"ALLSKY_days_ideal_rep\", \"ALLSKY_days_low_veg\",\n",
    "                           \"ALLSKY_days_low_rep\", \"ALLSKY_days_high_veg\", \"ALLSKY_days_high_rep\",\n",
    "                           \"RH2M_days_ideal_veg\", \"RH2M_days_high_veg\", \"RH2M_days_very_high_veg\",\n",
    "                           \"RH2M_days_very_high_veg\", \"NDVI_li_5\", \"NDVI_li_6\", \"NDVI_li_7\", \"NDVI_li_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692a90a2-636a-4a9c-aeb5-ba372e0329ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features = ['GDD_sum_veg', 'GDD_sum_rep',\n",
    "               'PTU_sum_veg', 'PTU_sum_rep',\n",
    "               'VPD_sum_veg', 'VPD_sum_rep',\n",
    "               'ALLSKY_NDVI_5', 'ALLSKY_NDVI_6',\n",
    "               'ALLSKY_NDVI_7', 'ALLSKY_NDVI_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604366c6-1dc1-40ca-9f77-59654f670832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/weather_NDVI_harvest.csv').copy()\n",
    "\n",
    "ndvi_cols = ['NDVI_li_5', 'NDVI_li_6', 'NDVI_li_7', 'NDVI_li_8']\n",
    "months_list = [5, 6, 7, 8]\n",
    "# ALLSKY x NDVI each month\n",
    "for month in months_list:\n",
    "    df[f'ALLSKY_NDVI_{month}'] = df[f'ALLSKY_{month}'] * df[f'NDVI_li_{month}']\n",
    "\n",
    "df = df.drop(columns=features_less_important)\n",
    "df = add_yearly_averages(df=df, features_to_average=key_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0d276e-3fce-4302-8d9f-af511d24be6d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_city_historical_mean_feature(df_train, df_test, year_predict):\n",
    "    \"\"\"\n",
    "    Adds a feature representing the historical mean productivity per city\n",
    "    for a given prediction year, avoiding lookahead bias.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame containing at least city, year, and target columns.\n",
    "        year_predict (int): The year to isolate as validation/test. Data before this year is used to compute means.\n",
    "        city_col (str): Name of the column indicating city/region.\n",
    "        target_col (str): Name of the column containing the productivity target.\n",
    "        fillna_global_mean (bool): Whether to fill missing cities in test set with global mean from training.\n",
    "\n",
    "    Returns:\n",
    "        tuple (pd.DataFrame, pd.DataFrame): Modified training and test DataFrames with the new feature.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary with the mean yield per city (no lookahead!)\n",
    "    mean_yield_by_city = df_train.groupby('市町村名')['Productivity'].mean().to_dict()\n",
    "\n",
    "    # Assign the mean values directly to X_train, like a fit_transform\n",
    "    df_train['mean_productivity_city'] = df_train['市町村名'].map(mean_yield_by_city)\n",
    "\n",
    "    # Apply the same mean values to the corresponding cities in X_test, like a transform\n",
    "    df_test['mean_productivity_city'] = df_test['市町村名'].map(mean_yield_by_city)\n",
    "    \n",
    "    # Obtain X_train, X_test, y_train, y_test\n",
    "    y_train = df_train['Productivity']\n",
    "    y_test = df_test['Productivity']\n",
    "\n",
    "    X_train = df_train.drop(columns=['市町村名', 'Productivity', 'year'])\n",
    "    X_test = df_test.drop(columns=['市町村名', 'Productivity', 'year'])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b8997-3120-48ef-9896-64d5545d3c63",
   "metadata": {},
   "source": [
    "### 2022 test:\n",
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd103e21-2c9d-427d-bd8c-907eea60ac51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing Assessment — RMSE: 26.1345\n",
      "📊 Model Performance Comparison:\n",
      "\n",
      "| Model                      |    RMSE |     MAE |     R² |   MedianAE |   MAPE (%) |\n",
      "|:---------------------------|--------:|--------:|-------:|-----------:|-----------:|\n",
      "| LGBMR_model (trimmed mean) | 26.1345 | 19.9692 | 0.7781 |    17.1617 |     3.5375 |\n",
      "| Baseline (trimmed mean)    | 28.7381 | 21.8830 | 0.7317 |    19.7500 |     3.8525 |\n",
      "| Baseline (mean)            | 32.0963 | 25.7849 | 0.6653 |    23.8125 |     4.5316 |\n"
     ]
    }
   ],
   "source": [
    "# --------- Configuration ---------\n",
    "year_predict = 2022\n",
    "\n",
    "# --------- Prepare empty results ---------\n",
    "results = []\n",
    "\n",
    "# --------- Model 1: LGBMR_model with trimmed_mean_productivity_city ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "model_2022 = LGBMR_model(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "y_pred_model = model_2022.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"LGBMR_model (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_model, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_model),\n",
    "    \"R²\": r2_score(y_test, y_pred_model),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_model),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_model) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 2: Trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_trimmed_baseline = X_test['trimmed_mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_trimmed_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"R²\": r2_score(y_test, y_pred_trimmed_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_trimmed_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 3: Non-trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_mean_baseline = X_test['mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_mean_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"R²\": r2_score(y_test, y_pred_mean_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_mean_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Show Results ---------\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"📊 Model Performance Comparison:\\n\")\n",
    "print(df_results.to_markdown(index=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003411f0-4ba6-4efe-b58a-ca27122e07fb",
   "metadata": {},
   "source": [
    "### 2023 test:\n",
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483dd1fe-b5d3-4b7f-aa1f-813f8dde5bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing Assessment — RMSE: 18.1711\n",
      "📊 Model Performance Comparison:\n",
      "\n",
      "| Model                      |    RMSE |     MAE |     R² |   MedianAE |   MAPE (%) |\n",
      "|:---------------------------|--------:|--------:|-------:|-----------:|-----------:|\n",
      "| LGBMR_model (trimmed mean) | 18.1711 | 12.3202 | 0.8697 |     7.5117 |     2.3298 |\n",
      "| Baseline (trimmed mean)    | 17.8918 | 13.3606 | 0.8737 |    10.7143 |     2.4636 |\n",
      "| Baseline (mean)            | 20.0963 | 16.3258 | 0.8407 |    14.4444 |     2.9839 |\n"
     ]
    }
   ],
   "source": [
    "# --------- Configuration ---------\n",
    "year_predict = 2023\n",
    "\n",
    "# --------- Prepare empty results ---------\n",
    "results = []\n",
    "\n",
    "# --------- Model 1: LGBMR_model with trimmed_mean_productivity_city ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "model_2022 = LGBMR_model(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "y_pred_model = model_2022.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"LGBMR_model (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_model, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_model),\n",
    "    \"R²\": r2_score(y_test, y_pred_model),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_model),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_model) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 2: Trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_trimmed_baseline = X_test['trimmed_mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_trimmed_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"R²\": r2_score(y_test, y_pred_trimmed_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_trimmed_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 3: Non-trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_mean_baseline = X_test['mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_mean_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"R²\": r2_score(y_test, y_pred_mean_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_mean_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Show Results ---------\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"📊 Model Performance Comparison:\\n\")\n",
    "print(df_results.to_markdown(index=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe137f7-e2d9-4679-a34a-1e49140b38aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['作付面積', 'PTU_sum_veg', 'PTU_sum_rep', 'VPD_sum_veg', 'VPD_sum_rep',\n",
       "       'GDD_sum_veg', 'GDD_sum_rep', 'stress_combo_days_veg',\n",
       "       'stress_combo_days_rep', 'ideal_combo_days_veg', 'ideal_combo_days_rep',\n",
       "       'ALLSKY_days_extremely_low_veg', 'ALLSKY_days_extremely_low_rep',\n",
       "       'ALLSKY_5', 'ALLSKY_6', 'ALLSKY_7', 'ALLSKY_8', 'RH2M_days_ideal_rep',\n",
       "       'RH2M_days_high_rep', 'RH2M_days_very_high_rep', 'T2M_5', 'T2M_6',\n",
       "       'T2M_7', 'T2M_8', '緯度', '経度', 'ALLSKY_NDVI_5', 'ALLSKY_NDVI_6',\n",
       "       'ALLSKY_NDVI_7', 'ALLSKY_NDVI_8', 'year_average_GDD_sum_veg',\n",
       "       'year_average_GDD_sum_rep', 'year_average_PTU_sum_veg',\n",
       "       'year_average_PTU_sum_rep', 'year_average_VPD_sum_veg',\n",
       "       'year_average_VPD_sum_rep', 'year_average_ALLSKY_NDVI_5',\n",
       "       'year_average_ALLSKY_NDVI_6', 'year_average_ALLSKY_NDVI_7',\n",
       "       'year_average_ALLSKY_NDVI_8', 'mean_productivity_city'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135c0bd-cf16-4713-a2d3-5e304e7da089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
