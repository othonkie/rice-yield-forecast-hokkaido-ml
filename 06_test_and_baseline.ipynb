{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be656135-15c4-4ff5-a818-48da5976367b",
   "metadata": {},
   "source": [
    "# Pipeline & Test\n",
    "____________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91de189-9b5a-41cd-9e4c-036aa219f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import resreg\n",
    "import itertools\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c6569f-57f3-4dc6-b0cb-a3c468ff5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_aware_train_test_split(df, year_predict, provide_X_y=False):\n",
    "    # Train test split\n",
    "    df_train = df[df['year'] < year_predict].copy()\n",
    "    df_test = df[df['year'] == year_predict].copy()\n",
    "    \n",
    "    if provide_X_y:\n",
    "        # Obtain X_train, X_test, y_train, y_test\n",
    "        y_train = df_train['Productivity']\n",
    "        y_test = df_test['Productivity']\n",
    "\n",
    "        X_train = df_train.drop(columns=['Â∏ÇÁî∫ÊùëÂêç', 'Productivity', 'year'])\n",
    "        X_test = df_test.drop(columns=['Â∏ÇÁî∫ÊùëÂêç', 'Productivity', 'year'])\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007cb51b-8014-4dbf-a616-db394a18ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmed_add_city_historical_mean_feature(df_train, df_test, year_predict):\n",
    "    \"\"\"\n",
    "    Adds a feature representing the historical trimmed mean productivity per city\n",
    "    for a given prediction year, avoiding lookahead bias.\n",
    "\n",
    "    For each city, the minimum and maximum productivity values are excluded \n",
    "    before calculating the mean.\n",
    "\n",
    "    Returns:\n",
    "        tuple (pd.DataFrame, pd.DataFrame): Modified training and test DataFrames with the new feature.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dictionary: trimmed mean productivity per city (excluding min and max)\n",
    "    mean_yield_by_city = {}\n",
    "    for city, group in df_train.groupby('Â∏ÇÁî∫ÊùëÂêç')['Productivity']:\n",
    "        if len(group) > 2:\n",
    "            trimmed_group = group.drop([group.idxmin(), group.idxmax()])\n",
    "            mean_yield_by_city[city] = trimmed_group.mean()\n",
    "        else:\n",
    "            # If there are only 2 or fewer values, just take the regular mean\n",
    "            mean_yield_by_city[city] = group.mean()\n",
    "\n",
    "    # Assign the trimmed mean values to training set\n",
    "    df_train['trimmed_mean_productivity_city'] = df_train['Â∏ÇÁî∫ÊùëÂêç'].map(mean_yield_by_city)\n",
    "\n",
    "    # Apply the same trimmed mean values to test set\n",
    "    df_test['trimmed_mean_productivity_city'] = df_test['Â∏ÇÁî∫ÊùëÂêç'].map(mean_yield_by_city)\n",
    "    \n",
    "    # Separate features and target\n",
    "    y_train = df_train['Productivity']\n",
    "    y_test = df_test['Productivity']\n",
    "\n",
    "    X_train = df_train.drop(columns=['Â∏ÇÁî∫ÊùëÂêç', 'Productivity', 'year'])\n",
    "    X_test = df_test.drop(columns=['Â∏ÇÁî∫ÊùëÂêç', 'Productivity', 'year'])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feb3357-20ca-4cdd-962f-1ce46cbe134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_yearly_averages(df, features_to_average):\n",
    "    \"\"\"\n",
    "    Computes the year average for selected features and adds them\n",
    "    as new features with suffix '_year_average'.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original DataFrame with a 'year' column.\n",
    "        features_to_average (list): List of feature names (str) to compute year averages.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with new '_year_average' features added.\n",
    "    \"\"\"\n",
    "    # Compute mean per year only for selected features\n",
    "    yearly_means = df.groupby('year')[features_to_average].mean()\n",
    "    yearly_means = yearly_means.add_prefix('year_average_').reset_index()\n",
    "\n",
    "    # Merge back into the original DataFrame\n",
    "    df = df.merge(yearly_means, on='year', how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c123376d-ea9c-4c97-b650-a6bc41bea6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGBMR_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Quickly evaluates the performance of a model after preprocessing,\n",
    "    using a balanced LightGBM configuration.\n",
    "    \"\"\"\n",
    "    model = LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='rmse',\n",
    "        num_leaves=31,\n",
    "        max_depth=4,\n",
    "        min_child_samples=30,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.8,\n",
    "        learning_rate=0.10,\n",
    "        n_estimators=100,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=0.0,\n",
    "        random_state=42,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "    print(f\"‚úÖ Preprocessing Assessment ‚Äî RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c00205-04ea-4d25-8caa-d25f7143246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_less_important = [\"Â∏ÇÁî∫Êùë„Ç≥„Éº„Éâ\", \"NDVI_li_9\", \"NDVI_li_10\",\n",
    "                           \"ET0_sum_veg\", \"ET0_sum_rep\", \"PTI_sum_veg\", \"PTI_sum_rep\",\n",
    "                           \"SWD_sum_veg\", \"SWD_sum_rep\", \"SWD_mean_rep\", \"SWD_mean_veg\",\n",
    "                           \"T2M_days_ideal_vegetative\", \"T2M_days_ideal_reproductive\",\n",
    "                           \"T2M_days_low_vegetative\", \"T2M_days_low_reproductive\",\n",
    "                           \"T2M_days_extremely_low_vegetative\", \"T2M_days_extremely_low_reproductive\",\n",
    "                           \"ALLSKY_days_ideal_veg\", \"ALLSKY_days_ideal_rep\", \"ALLSKY_days_low_veg\",\n",
    "                           \"ALLSKY_days_low_rep\", \"ALLSKY_days_high_veg\", \"ALLSKY_days_high_rep\",\n",
    "                           \"RH2M_days_ideal_veg\", \"RH2M_days_high_veg\", \"RH2M_days_very_high_veg\",\n",
    "                           \"RH2M_days_very_high_veg\", \"NDVI_li_5\", \"NDVI_li_6\", \"NDVI_li_7\", \"NDVI_li_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692a90a2-636a-4a9c-aeb5-ba372e0329ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features = ['GDD_sum_veg', 'GDD_sum_rep',\n",
    "               'PTU_sum_veg', 'PTU_sum_rep',\n",
    "               'VPD_sum_veg', 'VPD_sum_rep',\n",
    "               'ALLSKY_NDVI_5', 'ALLSKY_NDVI_6',\n",
    "               'ALLSKY_NDVI_7', 'ALLSKY_NDVI_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604366c6-1dc1-40ca-9f77-59654f670832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/weather_NDVI_harvest.csv').copy()\n",
    "\n",
    "ndvi_cols = ['NDVI_li_5', 'NDVI_li_6', 'NDVI_li_7', 'NDVI_li_8']\n",
    "months_list = [5, 6, 7, 8]\n",
    "# ALLSKY x NDVI each month\n",
    "for month in months_list:\n",
    "    df[f'ALLSKY_NDVI_{month}'] = df[f'ALLSKY_{month}'] * df[f'NDVI_li_{month}']\n",
    "\n",
    "df = df.drop(columns=features_less_important)\n",
    "df = add_yearly_averages(df=df, features_to_average=key_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0d276e-3fce-4302-8d9f-af511d24be6d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_city_historical_mean_feature(df_train, df_test, year_predict):\n",
    "    \"\"\"\n",
    "    Adds a feature representing the historical mean productivity per city\n",
    "    for a given prediction year, avoiding lookahead bias.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame containing at least city, year, and target columns.\n",
    "        year_predict (int): The year to isolate as validation/test. Data before this year is used to compute means.\n",
    "        city_col (str): Name of the column indicating city/region.\n",
    "        target_col (str): Name of the column containing the productivity target.\n",
    "        fillna_global_mean (bool): Whether to fill missing cities in test set with global mean from training.\n",
    "\n",
    "    Returns:\n",
    "        tuple (pd.DataFrame, pd.DataFrame): Modified training and test DataFrames with the new feature.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary with the mean yield per city (no lookahead!)\n",
    "    mean_yield_by_city = df_train.groupby('Â∏ÇÁî∫ÊùëÂêç')['Productivity'].mean().to_dict()\n",
    "\n",
    "    # Assign the mean values directly to X_train, like a fit_transform\n",
    "    df_train['mean_productivity_city'] = df_train['Â∏ÇÁî∫ÊùëÂêç'].map(mean_yield_by_city)\n",
    "\n",
    "    # Apply the same mean values to the corresponding cities in X_test, like a transform\n",
    "    df_test['mean_productivity_city'] = df_test['Â∏ÇÁî∫ÊùëÂêç'].map(mean_yield_by_city)\n",
    "    \n",
    "    # Obtain X_train, X_test, y_train, y_test\n",
    "    y_train = df_train['Productivity']\n",
    "    y_test = df_test['Productivity']\n",
    "\n",
    "    X_train = df_train.drop(columns=['Â∏ÇÁî∫ÊùëÂêç', 'Productivity', 'year'])\n",
    "    X_test = df_test.drop(columns=['Â∏ÇÁî∫ÊùëÂêç', 'Productivity', 'year'])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b8997-3120-48ef-9896-64d5545d3c63",
   "metadata": {},
   "source": [
    "### 2022 test:\n",
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd103e21-2c9d-427d-bd8c-907eea60ac51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing Assessment ‚Äî RMSE: 26.1345\n",
      "üìä Model Performance Comparison:\n",
      "\n",
      "| Model                      |    RMSE |     MAE |     R¬≤ |   MedianAE |   MAPE (%) |\n",
      "|:---------------------------|--------:|--------:|-------:|-----------:|-----------:|\n",
      "| LGBMR_model (trimmed mean) | 26.1345 | 19.9692 | 0.7781 |    17.1617 |     3.5375 |\n",
      "| Baseline (trimmed mean)    | 28.7381 | 21.8830 | 0.7317 |    19.7500 |     3.8525 |\n",
      "| Baseline (mean)            | 32.0963 | 25.7849 | 0.6653 |    23.8125 |     4.5316 |\n"
     ]
    }
   ],
   "source": [
    "# --------- Configuration ---------\n",
    "year_predict = 2022\n",
    "\n",
    "# --------- Prepare empty results ---------\n",
    "results = []\n",
    "\n",
    "# --------- Model 1: LGBMR_model with trimmed_mean_productivity_city ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "model_2022 = LGBMR_model(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "y_pred_model = model_2022.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"LGBMR_model (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_model, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_model),\n",
    "    \"R¬≤\": r2_score(y_test, y_pred_model),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_model),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_model) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 2: Trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_trimmed_baseline = X_test['trimmed_mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_trimmed_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"R¬≤\": r2_score(y_test, y_pred_trimmed_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_trimmed_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 3: Non-trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_mean_baseline = X_test['mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_mean_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"R¬≤\": r2_score(y_test, y_pred_mean_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_mean_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Show Results ---------\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"üìä Model Performance Comparison:\\n\")\n",
    "print(df_results.to_markdown(index=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003411f0-4ba6-4efe-b58a-ca27122e07fb",
   "metadata": {},
   "source": [
    "### 2023 test:\n",
    "________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483dd1fe-b5d3-4b7f-aa1f-813f8dde5bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing Assessment ‚Äî RMSE: 18.1711\n",
      "üìä Model Performance Comparison:\n",
      "\n",
      "| Model                      |    RMSE |     MAE |     R¬≤ |   MedianAE |   MAPE (%) |\n",
      "|:---------------------------|--------:|--------:|-------:|-----------:|-----------:|\n",
      "| LGBMR_model (trimmed mean) | 18.1711 | 12.3202 | 0.8697 |     7.5117 |     2.3298 |\n",
      "| Baseline (trimmed mean)    | 17.8918 | 13.3606 | 0.8737 |    10.7143 |     2.4636 |\n",
      "| Baseline (mean)            | 20.0963 | 16.3258 | 0.8407 |    14.4444 |     2.9839 |\n"
     ]
    }
   ],
   "source": [
    "# --------- Configuration ---------\n",
    "year_predict = 2023\n",
    "\n",
    "# --------- Prepare empty results ---------\n",
    "results = []\n",
    "\n",
    "# --------- Model 1: LGBMR_model with trimmed_mean_productivity_city ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "model_2022 = LGBMR_model(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "y_pred_model = model_2022.predict(X_test)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"LGBMR_model (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_model, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_model),\n",
    "    \"R¬≤\": r2_score(y_test, y_pred_model),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_model),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_model) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 2: Trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trimmed_add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_trimmed_baseline = X_test['trimmed_mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (trimmed mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_trimmed_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"R¬≤\": r2_score(y_test, y_pred_trimmed_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_trimmed_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_trimmed_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Model 3: Non-trimmed mean baseline ---------\n",
    "df_train, df_test = temporal_aware_train_test_split(df=df, year_predict=year_predict)\n",
    "\n",
    "X_train, X_test, y_train, y_test = add_city_historical_mean_feature(\n",
    "    df_train=df_train, df_test=df_test, year_predict=year_predict\n",
    ")\n",
    "\n",
    "y_pred_mean_baseline = X_test['mean_productivity_city']\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Baseline (mean)\",\n",
    "    \"RMSE\": mean_squared_error(y_test, y_pred_mean_baseline, squared=False),\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"R¬≤\": r2_score(y_test, y_pred_mean_baseline),\n",
    "    \"MedianAE\": median_absolute_error(y_test, y_pred_mean_baseline),\n",
    "    \"MAPE (%)\": np.mean(np.abs((y_test - y_pred_mean_baseline) / y_test)) * 100\n",
    "})\n",
    "\n",
    "\n",
    "# --------- Show Results ---------\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"üìä Model Performance Comparison:\\n\")\n",
    "print(df_results.to_markdown(index=False, floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe137f7-e2d9-4679-a34a-1e49140b38aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['‰Ωú‰ªòÈù¢Á©ç', 'PTU_sum_veg', 'PTU_sum_rep', 'VPD_sum_veg', 'VPD_sum_rep',\n",
       "       'GDD_sum_veg', 'GDD_sum_rep', 'stress_combo_days_veg',\n",
       "       'stress_combo_days_rep', 'ideal_combo_days_veg', 'ideal_combo_days_rep',\n",
       "       'ALLSKY_days_extremely_low_veg', 'ALLSKY_days_extremely_low_rep',\n",
       "       'ALLSKY_5', 'ALLSKY_6', 'ALLSKY_7', 'ALLSKY_8', 'RH2M_days_ideal_rep',\n",
       "       'RH2M_days_high_rep', 'RH2M_days_very_high_rep', 'T2M_5', 'T2M_6',\n",
       "       'T2M_7', 'T2M_8', 'Á∑ØÂ∫¶', 'ÁµåÂ∫¶', 'ALLSKY_NDVI_5', 'ALLSKY_NDVI_6',\n",
       "       'ALLSKY_NDVI_7', 'ALLSKY_NDVI_8', 'year_average_GDD_sum_veg',\n",
       "       'year_average_GDD_sum_rep', 'year_average_PTU_sum_veg',\n",
       "       'year_average_PTU_sum_rep', 'year_average_VPD_sum_veg',\n",
       "       'year_average_VPD_sum_rep', 'year_average_ALLSKY_NDVI_5',\n",
       "       'year_average_ALLSKY_NDVI_6', 'year_average_ALLSKY_NDVI_7',\n",
       "       'year_average_ALLSKY_NDVI_8', 'mean_productivity_city'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135c0bd-cf16-4713-a2d3-5e304e7da089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
